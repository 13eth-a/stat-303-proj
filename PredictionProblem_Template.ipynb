{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5dbbea0e-3a99-459e-abd6-0959e6946869",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Prediction Problem\"\n",
    "subtitle: \"STAT 303-3 Spring 25\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    code-fold: show\n",
    "    embed-resources: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec7523b-6099-4001-a997-60005980e73a",
   "metadata": {},
   "source": [
    "## Instructions:\n",
    "\n",
    "- Put the parts of your code under the corresponding sections. (0.25/2 points will be taken off for not doing this.)\n",
    "- Do not include any redundant/irrelevant code, text or comments. (0.5/2 points will be taken off for not doing this.)\n",
    "- **Your code must run without any errors or runtime issues.** (Failure to meet this condition will result in a 0.)\n",
    "- **Your code must return your Public Leaderboard score.** (Failure to meet this condition will result in a 0.)\n",
    "- **Submit both your ipynb and your html file for grading purposes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03031cca-1a24-4e66-926e-2b32f85f3cc7",
   "metadata": {},
   "source": [
    "## 1) Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d65f439-927b-4b40-9008-a715356fbe58",
   "metadata": {},
   "source": [
    "Put all the Python libraries and tools you imported here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eb866b1-8f62-4ca4-a39e-5774486da357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1877d116-1e8d-426e-84ba-10c47e28a1ac",
   "metadata": {},
   "source": [
    "## 2) Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177363af-51a7-4b16-b6d2-33ba5796bd20",
   "metadata": {},
   "source": [
    "- This section is required to include the code that reads, cleans and preprocesses the datasets.\n",
    "- Note that both the training and test datasets should undergo the same sequence of operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddcc4a5b-777a-4b75-8fd7-b0594591ea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train2 = train.copy()\n",
    "train2['price'] = train2['price'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "drop_cols = ['id', 'description', 'host_about', 'host_name', 'first_review', 'last_review', 'host_verifications', 'listing_location']\n",
    "train2 = train2.drop(columns=[col for col in drop_cols if col in train2.columns])\n",
    "\n",
    "test = test.drop(columns=[col for col in drop_cols if col in test.columns and col != 'id'])\n",
    "\n",
    "for col in ['host_response_rate', 'host_acceptance_rate']:\n",
    "    train2[col] = train2[col].str.rstrip('%').astype(float) / 100\n",
    "    test[col] = test[col].str.rstrip('%').astype(float) / 100\n",
    "\n",
    "train2['bathrooms'] = train2['bathrooms_text'].str.extract('(\\d+\\.?\\d*)').astype(float)\n",
    "test['bathrooms'] = test['bathrooms_text'].str.extract('(\\d+\\.?\\d*)').astype(float)\n",
    "train2 = train2.drop(columns=['bathrooms_text'])\n",
    "test = test.drop(columns=['bathrooms_text'])\n",
    "\n",
    "train2['host_since'] = pd.to_datetime(train2['host_since'], errors='coerce')\n",
    "test['host_since'] = pd.to_datetime(test['host_since'], errors='coerce')\n",
    "train2['host_since_days'] = (pd.to_datetime('2023-01-01') - train2['host_since']).dt.days\n",
    "test['host_since_days'] = (pd.to_datetime('2023-01-01') - test['host_since']).dt.days\n",
    "train2 = train2.drop(columns=['host_since'])\n",
    "test = test.drop(columns=['host_since'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7353233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cardinality = train2.select_dtypes(include=['object', 'bool']).nunique()\n",
    "high_card_cols = cardinality[cardinality > 100].index.tolist()\n",
    "\n",
    "X = train2.drop(columns=['price'] + high_card_cols)\n",
    "y = np.log1p(train2['price']) \n",
    "\n",
    "categorical_cols = X.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "for col in categorical_cols:\n",
    "    freq = X[col].value_counts(normalize=True)\n",
    "    X[col + '_freq'] = X[col].map(freq)\n",
    "X = X.drop(columns=categorical_cols)\n",
    "\n",
    "test_ids = test['id']\n",
    "X_test = test.drop(columns=[col for col in high_card_cols if col in test.columns])\n",
    "for col in categorical_cols:\n",
    "    freq = train[col].value_counts(normalize=True)\n",
    "    X_test[col + '_freq'] = test[col].map(freq)\n",
    "X_test = X_test.drop(columns=[col for col in categorical_cols if col in X_test.columns])\n",
    "X_test = X_test.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "outlier_price = 20000\n",
    "X_train = X_train[y_train < outlier_price]\n",
    "y_train = y_train[y_train < outlier_price]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1078e4fa-9a22-44ca-b1e3-944f25dac70a",
   "metadata": {},
   "source": [
    "## 3) Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa5c8b4-9aab-4022-8561-5f8bf964cab3",
   "metadata": {},
   "source": [
    "- This section is required to train the **already tuned** model and obtain the test predictions (or prediction probabilities) with it.\n",
    "- As written in the instructions, your code must not have any runtime issues, so **do NOT include your grid search here!** You will still need to tune your model to pass the thresholds. However, you need to keep that as your personal work and should NOT include the grid search here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80ccfd51-090e-4685-a4fc-d26c8fbe12d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE: 87.11\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(\n",
    "    n_estimators=1600,\n",
    "    learning_rate=0.016515151515151517,\n",
    "    max_depth=8,\n",
    "    min_child_weight=1,\n",
    "    subsample=0.6838383838383838,\n",
    "    colsample_bytree=0.6484848484848484,\n",
    "    gamma=0.0030303030303030303,\n",
    "    reg_lambda=0.20408163265306123,\n",
    "    scale_pos_weight=24,\n",
    "    objective='reg:squarederror',\n",
    "    random_state=1\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_valid)\n",
    "mae = mean_absolute_error(np.expm1(y_valid), np.expm1(y_pred))\n",
    "print(f\"Validation MAE: {mae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc2d1c1-edd2-428c-9944-2bafc8f9291b",
   "metadata": {},
   "source": [
    "## 4) Exporting the Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e92cdc-e3e0-423a-a248-cf3b1cf99f68",
   "metadata": {},
   "source": [
    "Include the code that (1) puts the predictions in the format that Kaggle understands and (2) exports it as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1f881e2-bccf-49e3-aa6c-ff4381883031",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = xgb.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'price': np.expm1(y_test_pred) \n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asiignment0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
